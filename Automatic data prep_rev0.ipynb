{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import vstack\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "from random import seed\n",
    "from random import randint\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use this link for dataprep:\n",
    "    https://scikit-learn.org/stable/modules/preprocessing.html#standardization-or-mean-removal-and-variance-scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>At1</th>\n",
       "      <th>At2</th>\n",
       "      <th>At3</th>\n",
       "      <th>At4</th>\n",
       "      <th>At5</th>\n",
       "      <th>At6</th>\n",
       "      <th>At7</th>\n",
       "      <th>At8</th>\n",
       "      <th>At9</th>\n",
       "      <th>At10</th>\n",
       "      <th>...</th>\n",
       "      <th>At12</th>\n",
       "      <th>At13</th>\n",
       "      <th>At14</th>\n",
       "      <th>At15</th>\n",
       "      <th>At16</th>\n",
       "      <th>At17</th>\n",
       "      <th>At18</th>\n",
       "      <th>At19</th>\n",
       "      <th>At20</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A11</td>\n",
       "      <td>6</td>\n",
       "      <td>A34</td>\n",
       "      <td>A43</td>\n",
       "      <td>1169</td>\n",
       "      <td>A65</td>\n",
       "      <td>A75</td>\n",
       "      <td>4</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A121</td>\n",
       "      <td>67</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>2</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A192</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A12</td>\n",
       "      <td>48</td>\n",
       "      <td>A32</td>\n",
       "      <td>A43</td>\n",
       "      <td>5951</td>\n",
       "      <td>A61</td>\n",
       "      <td>A73</td>\n",
       "      <td>2</td>\n",
       "      <td>A92</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A121</td>\n",
       "      <td>22</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>1</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A14</td>\n",
       "      <td>12</td>\n",
       "      <td>A34</td>\n",
       "      <td>A46</td>\n",
       "      <td>2096</td>\n",
       "      <td>A61</td>\n",
       "      <td>A74</td>\n",
       "      <td>2</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A121</td>\n",
       "      <td>49</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>1</td>\n",
       "      <td>A172</td>\n",
       "      <td>2</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A11</td>\n",
       "      <td>42</td>\n",
       "      <td>A32</td>\n",
       "      <td>A42</td>\n",
       "      <td>7882</td>\n",
       "      <td>A61</td>\n",
       "      <td>A74</td>\n",
       "      <td>2</td>\n",
       "      <td>A93</td>\n",
       "      <td>A103</td>\n",
       "      <td>...</td>\n",
       "      <td>A122</td>\n",
       "      <td>45</td>\n",
       "      <td>A143</td>\n",
       "      <td>A153</td>\n",
       "      <td>1</td>\n",
       "      <td>A173</td>\n",
       "      <td>2</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A11</td>\n",
       "      <td>24</td>\n",
       "      <td>A33</td>\n",
       "      <td>A40</td>\n",
       "      <td>4870</td>\n",
       "      <td>A61</td>\n",
       "      <td>A73</td>\n",
       "      <td>3</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A124</td>\n",
       "      <td>53</td>\n",
       "      <td>A143</td>\n",
       "      <td>A153</td>\n",
       "      <td>2</td>\n",
       "      <td>A173</td>\n",
       "      <td>2</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   At1  At2  At3  At4   At5  At6  At7  At8  At9  At10  ...  At12 At13  At14  \\\n",
       "0  A11    6  A34  A43  1169  A65  A75    4  A93  A101  ...  A121   67  A143   \n",
       "1  A12   48  A32  A43  5951  A61  A73    2  A92  A101  ...  A121   22  A143   \n",
       "2  A14   12  A34  A46  2096  A61  A74    2  A93  A101  ...  A121   49  A143   \n",
       "3  A11   42  A32  A42  7882  A61  A74    2  A93  A103  ...  A122   45  A143   \n",
       "4  A11   24  A33  A40  4870  A61  A73    3  A93  A101  ...  A124   53  A143   \n",
       "\n",
       "   At15 At16  At17 At18  At19  At20  Y  \n",
       "0  A152    2  A173    1  A192  A201  1  \n",
       "1  A152    1  A173    1  A191  A201  2  \n",
       "2  A152    1  A172    2  A191  A201  1  \n",
       "3  A153    1  A173    2  A191  A201  1  \n",
       "4  A153    2  A173    2  A191  A201  2  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_path= \"C:/Users/Minaz/OneDrive - HEC Montréal/Travail/Desjardins/R&D/GRAD/Data/German Credit/german.txt\"\n",
    "dataset=pd.read_csv(input_path, sep=\" \")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dataset=dataset.drop(\"Y\",axis=1)\n",
    "y_dataset=dataset.Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['At1', 'At2', 'At3', 'At4', 'At5', 'At6', 'At7', 'At8', 'At9', 'At10', 'At11', 'At12', 'At13', 'At14', 'At15', 'At16', 'At17', 'At18', 'At19', 'At20']\n",
      "['At1', 'At3', 'At4', 'At6', 'At7', 'At9', 'At10', 'At12', 'At14', 'At15', 'At17', 'At19', 'At20']\n",
      "['At2', 'At5', 'At8', 'At11', 'At13', 'At16', 'At18']\n"
     ]
    }
   ],
   "source": [
    "column_list=list(X_dataset.columns)\n",
    "object_cols =list(X_dataset.select_dtypes(include=['category','object','bool']))\n",
    "num_cols=[x for x in column_list if x not in object_cols]\n",
    "print(column_list)\n",
    "print(object_cols)\n",
    "print(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "At1     object\n",
       "At2      int64\n",
       "At3     object\n",
       "At4     object\n",
       "At5      int64\n",
       "At6     object\n",
       "At7     object\n",
       "At8      int64\n",
       "At9     object\n",
       "At10    object\n",
       "At11     int64\n",
       "At12    object\n",
       "At13     int64\n",
       "At14    object\n",
       "At15    object\n",
       "At16     int64\n",
       "At17    object\n",
       "At18     int64\n",
       "At19    object\n",
       "At20    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dataset_num=X_dataset.drop(object_cols,axis=1)\n",
    "X_dataset_cat=X_dataset[object_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Groupe together the less present modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-7-39a27be91f21>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-7-39a27be91f21>\"\u001b[1;36m, line \u001b[1;32m13\u001b[0m\n\u001b[1;33m    def train_valid_split(self): # split data in 2 data sets\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "class MinaReplace():\n",
    "    def __init__(self , data_X,data_y, list_of_columns = None , threshold = 0.0002  , valid_size = 0.3):\n",
    "        self.data_X = data_X             #The X data set\n",
    "        self.data_y = data_y             #The y data set\n",
    "        self.threshold = threshold   # The critaria that we use in replace phase\n",
    "        self.list_of_columns = list_of_columns #The list of the name of  all categroaicl columns in data table. \n",
    "        self.valid_size = valid_size  # Represent the proportion of the dataset to include in the valid split.\n",
    "    \n",
    "    def find_columns(self): # Find categorical columns; We develop tis function later\n",
    "        \n",
    "    \n",
    "    def train_valid_split(self): # split data in 2 data sets\n",
    "        \n",
    "        self.X_train, self.X_valid, self.y_train, self.y_valid = train_test_split(self.data_X,\n",
    "                                                                                  self.data_y, \n",
    "                                                                                  test_size = self.valid_size, \n",
    "                                                                                  random_state=42)\n",
    "    \n",
    "    def replace_in_train_valid(self , i):\n",
    "        mask = self.X_train[i].value_counts(normalize=True)< self.threshold\n",
    "        minority = self.X_train[i].value_counts(normalize=True)[mask].index.tolist() \n",
    "        self.d = dict() \n",
    "        for val in minority: \n",
    "            self.d[val]='Other'  #???? how to add name of column at the end of other? \n",
    "        self.X_train[i].replace(self.d,inplace=True) \n",
    "        self.X_valid[i].replace(self.d,inplace=True) \n",
    "\n",
    "\n",
    "    def main_function(self):\n",
    "        self.train_valid_split()\n",
    "        self.find_columns()\n",
    "        for i in self.list_of_columns:\n",
    "            self.replace_in_train_valid(i)\n",
    "        return(self.X_train, self.X_valid, self.y_train, self.y_valid)\n",
    "            \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MinaReplace' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-f19ba0536f10>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmina0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMinaReplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_X\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_y\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist_of_columns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobject_cols\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.05\u001b[0m  \u001b[1;33m,\u001b[0m \u001b[0mvalid_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'MinaReplace' is not defined"
     ]
    }
   ],
   "source": [
    "mina0=MinaReplace(data_X=X_dataset,data_y=y_dataset, list_of_columns = object_cols , threshold = 0.05  , valid_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Minaz\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6746: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "X_train_0,X_val_0,y_train_0,y_val_0=mina0.main_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A101     630\n",
       "A103      40\n",
       "Other     30\n",
       "Name: At10, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_0.At10.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Onehot encoding\n",
    "this function retuns a new train and valid dataset with the binary columns for all categorical columns. So this does contain NI the source categorical NOR numeric columns. JUST binary columns for categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "class MinaOneHot():\n",
    "    def __init__(self , X_train, X_valid, list_of_columns = None ):\n",
    "        self.X_train = X_train             #The data set\n",
    "        self.X_valid = X_valid             #The data set\n",
    "        self.list_of_columns = list_of_columns #The list of the name of  all categroaicl columns in data table. \n",
    "    \n",
    "    def find_columns(self): # Find categorical columns; We develop tis function later\n",
    "        pass\n",
    "      \n",
    "    def onehotencoder(self , i):\n",
    "        encode_1=LabelEncoder()                     # créer un objet de la classe LabelEncoder\n",
    "        encode_2=OneHotEncoder(categories='auto')   # créer un objet de la classe OneHotEncoder\n",
    "        # combiner l'application des deux classes\n",
    "        self.encode_X_train_array=encode_2.fit_transform(encode_1.fit_transform(self.X_train[i]).reshape(-1,1))\n",
    "        self.encode_X_valid_array=encode_2.transform(encode_1.transform(self.X_valid[i]).reshape(-1,1))\n",
    "        \n",
    "        self.encode_X_train_df=pd.DataFrame(self.encode_X_train_array.toarray(),columns=self.X_train[i].unique())\n",
    "        self.encode_X_valid_df=pd.DataFrame(self.encode_X_valid_array.toarray(),columns=self.X_valid[i].unique())\n",
    "        self.encode_X_train_df.drop(columns=self.encode_X_train_df.columns[-1], axis=1, inplace=True)\n",
    "        self.encode_X_valid_df.drop(columns=self.encode_X_valid_df.columns[-1], axis=1, inplace=True)\n",
    "\n",
    "    def main_function(self):\n",
    "        self.find_columns()\n",
    "        self.X_t=pd.DataFrame()\n",
    "        self.X_v=pd.DataFrame()\n",
    "        for i in self.list_of_columns:\n",
    "            self.onehotencoder(i)\n",
    "            self.X_t=pd.concat([self.X_t.reset_index(drop=True), self.encode_X_train_df], axis=1)\n",
    "            self.X_v=pd.concat([self.X_v.reset_index(drop=True), self.encode_X_valid_df], axis=1)\n",
    "        return(self.X_t,self.X_v)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-6c1c2562d096>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmina1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMinaOneHot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_val_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist_of_columns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobject_cols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_0' is not defined"
     ]
    }
   ],
   "source": [
    "mina1=MinaOneHot(X_train_0,X_val_0, list_of_columns = object_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1,X_val_1=mina1.main_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A14</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A33</th>\n",
       "      <th>A32</th>\n",
       "      <th>A34</th>\n",
       "      <th>A30</th>\n",
       "      <th>A40</th>\n",
       "      <th>A42</th>\n",
       "      <th>A41</th>\n",
       "      <th>...</th>\n",
       "      <th>A122</th>\n",
       "      <th>A143</th>\n",
       "      <th>A141</th>\n",
       "      <th>A153</th>\n",
       "      <th>A152</th>\n",
       "      <th>A173</th>\n",
       "      <th>A174</th>\n",
       "      <th>A172</th>\n",
       "      <th>A192</th>\n",
       "      <th>A201</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   A14  A11  A12  A33  A32  A34  A30  A40  A42  A41  ...  A122  A143  A141  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  ...   1.0   0.0   0.0   \n",
       "2  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  ...   0.0   0.0   0.0   \n",
       "3  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  ...   1.0   0.0   0.0   \n",
       "\n",
       "   A153  A152  A173  A174  A172  A192  A201  \n",
       "0   0.0   0.0   0.0   0.0   1.0   0.0   1.0  \n",
       "1   0.0   1.0   0.0   0.0   0.0   0.0   1.0  \n",
       "2   1.0   0.0   0.0   0.0   1.0   0.0   1.0  \n",
       "3   0.0   1.0   0.0   1.0   0.0   1.0   1.0  \n",
       "4   0.0   1.0   0.0   0.0   0.0   0.0   1.0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 37)\n",
      "(300, 37)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_1.shape)\n",
    "print(X_val_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. StandardScaler\n",
    "this function retuns a train and valid dataset of standardized numerical columns. So contains juste numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "class MinaStandscaler():\n",
    "    def __init__(self , X_train, X_valid,list_of_numeric_columns = None):\n",
    "        self.X_train = X_train             #The data set\n",
    "        self.X_valid = X_valid             #The data set\n",
    "        self.list_of_numeric_columns=list_of_numeric_columns\n",
    "    \n",
    "    def find_columns(self): # Find categorical columns; We develop tis function later\n",
    "        self.X_train_num=self.X_train[self.list_of_numeric_columns]\n",
    "        self.X_valid_num=self.X_valid[self.list_of_numeric_columns]\n",
    "      \n",
    "    def stand(self):\n",
    "        standardscale_1=StandardScaler().fit(self.X_train_num)                    # créer un objet de la classe StandardSclae\n",
    "        # combiner l'application des deux classes\n",
    "        standard_X_train_array=standardscale_1.transform(self.X_train_num)\n",
    "        standard_X_valid_array=standardscale_1.transform(self.X_valid_num)\n",
    "        \n",
    "        self.standard_X_train_df=pd.DataFrame(standard_X_train_array,columns=self.list_of_numeric_columns)\n",
    "        self.standard_X_valid_df=pd.DataFrame(standard_X_valid_array,columns=self.list_of_numeric_columns)\n",
    "\n",
    "    def main_function(self):\n",
    "        self.find_columns()\n",
    "        self.stand()\n",
    "        X_t_s=self.standard_X_train_df\n",
    "        X_v_s=self.standard_X_valid_df\n",
    "        return(X_t_s,X_v_s)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "mina2=MinaStandscaler(X_train_0,X_val_0,list_of_numeric_columns = num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2, X_val_2=mina2.main_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 7)\n",
      "(300, 7)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_2.shape)\n",
    "print(X_val_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic1={2:0}\n",
    "y_val=pd.DataFrame(y_val_0)\n",
    "y_val.Y.replace(dic1,inplace=True) \n",
    "\n",
    "y_train=pd.DataFrame(y_train_0)\n",
    "y_train.Y.replace(dic1,inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=pd.concat([X_train_1.reset_index(drop=True), X_train_2], axis=1)\n",
    "X_train=pd.concat([X_train.reset_index(drop=True), y_train.reset_index(drop=True)], axis=1)\n",
    "X_val=pd.concat([X_val_1.reset_index(drop=True), X_val_2], axis=1)\n",
    "X_val=pd.concat([X_val.reset_index(drop=True), y_val.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 45)\n",
      "(300, 45)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATTENTION: we need think about\n",
    "    - the NAs replacing strategy\n",
    "    - the date columns\n",
    "    - uper or lower case the values in columns before using 1st function\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(\"C:/Users/Minaz/OneDrive - HEC Montréal/Travail/Desjardins/R&D/GRAD/Data/German Credit/german_credit_cleaned_train.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.to_csv(\"C:/Users/Minaz/OneDrive - HEC Montréal/Travail/Desjardins/R&D/GRAD/Data/German Credit/german_credit_cleaned_val.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
